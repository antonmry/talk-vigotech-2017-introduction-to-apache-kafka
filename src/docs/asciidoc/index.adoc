= Introducción a Apache Kafka
Antón R. Yuste - @antonmry - OptareSolutions & VigoJUG
2017-06-12
:revnumber: {project-version}
:example-caption!:
ifndef::imagesdir[:imagesdir: images]
ifndef::sourcedir[:sourcedir: ../java]
:deckjs_transition: fade
:navigation:
:menu:
:status:
:adoctor: http://asciidoctor.org/[Asciidoctor]
:gradle: http://gradle.org[Gradle]

== E ti, ¿de quen ves sendo?

image::costadamorte.jpg[background, size=cover]

++++
<style>
.asciinema-terminal.font-medium {
  font-size: 16px;
}
</style>

<div class="pictureWrapper">
   <div class="picture"><img src="images/mini-me.png"></div>
</div>
++++


[source,groovy]
----
speaker = [
    name: 'Antón R. Yuste',
    company: 'Optare Solutions',
    role: 'Technical Director',
    twitter: '@antonmry',
    github: 'antonmry',
    extraDescription: ['VigoJUG co-organiser',
         '''Misc OSS contribs (Gradle plugins,
            docker images, SIP & WebRTC...)''',
         'surfer wannabe',]
].each{ k, v -> println "${k}:${v}" }
----

== Optare Solutions
// Presentar Optare
// Empecei de becario en 2007
// Expertos en orquestación e grandes sistemas en telco
image::optare.jpg[Optare]

== Frontend vs. Backend
image::front-back-end.png[Frontend vs. Back-end]

// Noticias: Telefónica co virus
// Noticias: British Airways
// Noticias: Knight Capital, una firma de inversión, que en 2012 perdió 500 millones de dólares en media hora en Bolsa

== Microservices
image::microservices.gif[Microservices]

// Definir os microservices, vantaxes e problemas

== Apache Kafka

> Apache Kafka es un proyecto de intermediación de mensajes de código abierto desarrollado por la Apache Software Foundation escrito en Scala.

Fonte: wikipedia

// Comentar que foi inicialmente feito por Linkedin

=== Apache Kafka

> El proyecto tiene como objetivo proporcionar una plataforma unificada, de alto rendimiento y de baja latencia para la manipulación en tiempo real de fuentes de datos.

Fonte: wikipedia

=== Apache Kafka

> Puede verse como una cola de mensajes, bajo el patrón publicación-suscripción, masivamente escalable concebida como un registro de transacciones distribuidas, la que la vuelve atractiva para las infraestructuras de aplicaciones empresariales.

Fonte: wikipedia

=== A miña definición: caixas máxicas

image::caixones.jpg[caixons]

// Podemos sacar varias copias da mesma cousa (ou soamente unha).
// O que metemos nunha biblioteca, pode sair noutra: distribuido.
// O que entra, sae no mesmo orde.

== Uso

image::Before_Kafka.png[Spaguetti Architecture]

=== Separar os servicios

image::With_KAFKA.png[Kafka definition of services]

=== Con Kafka

image::After_KAFKA.png[Architecture with Kafka]

=== Fonte

https://www.confluent.io/blog/stream-data-platform-1/[Putting Apache Kafka To Use: A Practical Guide to Building a Streaming Platform] - Confluent

== Arquitectura

image::architecture.png[Apache Kafka Architecture]

// Alta disponibilidade
// Replication factor 4
// Presentar ZooKeeper

=== Topic

image::topic.png[Apache Kafka Topic]

// Numerados -> manter o orden
// Round Robin por defecto
// Persistidos a disco (diferencia con Rabbit, memoria)
// Diferentes partitions -> diferentes brokers

=== Replication

image::replication.png[Apache Kafka Replication]

=== Fonte

http://kth.diva-portal.org/smash/get/diva2:813137/FULLTEXT01.pdf[Message-oriented Middleware for Scalable Data Analytics Architectures (NICOLAS NANNONI)]

== Rendemento
image::kafka-performance.png[Apache Kafka Performance]

=== Latencia
image::latency.jpg[Apache Kafka Latencia]

// Comentar como consigue este rendemento: ¡os conectores!

== Conectores

// Dispoñibles para moitos linguaxes

[cols="2a,2a"]
|===
|* Java
* C/C++
* Python
* Go (AKA golang)
* Erlang
* .NET
* Clojure
* Ruby
* Node.js
|* Proxy (HTTP REST, etc)
* Perl
* stdin/stdout
* PHP
* Rust
* Alternative Java
* Storm
* Scala DSL
* Clojure
|===

== Exemplo: refubot

image::refubot.png[Refubot con Apache Kafka]

=== ¡Funcionou!

image::refubot-presentacion.jpg[Presentacion Refubot]

== Casos de uso

Algúns exemplos habituais pero é unha ferramenta que soporta moitos usos.

=== Messaging

- Permite desaclopar sistemas tradicionais.
- Tamén para coordinar sistemas distribuidos.
- Exemplos: refubot, Bluemix, LivePerson.

=== Website Activity Tracking

- O volumen de datos xerados polos usuarios é moi alto.
- Ten moitos usos: estadísticas, monitoreo, seguridade, etc.
- Nalgún casos é preciso ter acceso a información en tempo real con accións immediatas.
- https://engineering.linkedin.com/blog/2016/04/kafka-ecosystem-at-linkedin[Linkedin], https://blog.twitter.com/engineering/en_us/a/2015/handling-five-billion-sessions-a-day-in-real-time.html[Twitter]

// Linkedin: over 1 trillion events / day

=== Métricas

- O sistema que as recibe pode non ser capaz de procesar todo o tráfico no momento que se produce: precisamos un "buffer".
- A información tense que persistir, incluso si algún dos servidores do "buffer" se cae.
- https://yahooeng.tumblr.com/post/109994930921/kafka-yahoo[Yahoo], https://medium.com/netflix-techblog/kafka-inside-keystone-pipeline-dd5aeabaf6bb[Netflix], https://eng.uber.com/tech-stack-part-two/[Uber], R-Cable Smart Home.

=== Agregación de Logs

- Sistema central para almacenar os logs de diferentes fontes antes de ser procesados.
- Hai ferramentas específicas pero Kafka ten menor latencia, o que nalgúns casos pode ser moi interesantes.
- Integracións con ELK.
- https://medium.com/@Pinterest_Engineering/introducing-pinterest-secor-e868d9400bec[Pinterest], https://www.meetup.com/stockholm-hug/events/121628932/[Spotify], trivago, cloudfare, graylog2, shopify

== Demo

image::demo.gif[Demo]

=== Posta en marcha e proba

[source,bash]
----
docker run -p 2181:2181 -p 9092:9092 --name kafka --hostname kafka --env ADVERTISED_HOST=kafka --env ADVERTISED_PORT=9092 spotify/kafka

docker exec -it kafka /bin/bash

$KAFKA_HOME/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic example

$KAFKA_HOME/bin/kafka-topics.sh --list --zookeeper localhost:2181

$KAFKA_HOME/bin/kafka-console-producer.sh --broker-list kafka:9092 --topic example

$KAFKA_HOME/bin/kafka-console-consumer.sh --bootstrap-server kafka:9092 --topic example --from-beginning

----

=== Cliente Python

[source,bash]
----
apt-get install python3 python3-dev python3-pip vim
pip3 install kafka-python
----

[source,python]
----
from kafka import KafkaProducer

producer = KafkaProducer(bootstrap_servers='kafka:9092')
producer.send('example', b'hello from python')
----

== Kafka Streams

=== A comunicación tradicional (sistemas acoplados)
image::before_stream.png[Fullfilment]

=== Basada en eventos
image::with_stream.png[Fullfilment Events Based]

=== Fluxo de negocio con streams

image::kafka_stream.png[Streams with Kafka]

// Here each color represents a topic, in Kafka, for Orders, Shipments and Payments.

=== Streams

[source,java]
----
KStream<String,Purchase> purchaseKStream =
kStreamBuilder.stream(stringSerde,purchaseSerde,"orders")
.mapValues(p -> Purchase.builder(p).maskCreditCard().build())
.to(stringSerde, purchasePatternSerde, "shipments");
----

=== Fonte

https://www.confluent.io/blog/build-services-backbone-events/[Build Services on a Backbone of Events] - Confluent

== Resumo

* Apache Kafka é doado e aporta vantaxes dende o primeiro minuto.
* Kafka Streams habilitan unha nova arquitectura que terá moito éxito.
* Moi útil para temas de IoT.


== ¡Gracias!

image::questions.jpg[background, size=cover]

* Slides: https://antonmry.github.io/talk-vigotech-2017-introduction-to-apache-kafka
* Código: https://github.com/antonmry/talk-vigotech-2017-introduction-to-apache-kafka
* Documentación Apache Kafka: https://kafka.apache.org/
* Tamén podes preguntarme en twitter: http://twitter.com/antonmry[@antonmry]

